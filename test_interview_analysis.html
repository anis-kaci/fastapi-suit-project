<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interview Video Analyzer</title>
    <!-- Tailwind CSS CDN -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Google Fonts - Inter -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        /* Custom spinner animation */
        .spinner {
            border: 4px solid rgba(0, 0, 0, 0.1);
            border-left-color: #6366f1; /* Tailwind indigo-500 */
            border-radius: 50%;
            width: 32px;
            height: 32px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
    </style>
</head>
<body class="bg-gray-100 flex items-center justify-center min-h-screen p-4">
    <div class="bg-white p-8 rounded-lg shadow-lg w-full max-w-2xl">
        <h1 class="text-3xl font-bold text-gray-800 mb-6 text-center">Analyseur de Vidéo d'Entretien IA</h1>
        <p class="text-gray-600 mb-6 text-center">Téléchargez une vidéo d'entretien pour obtenir une transcription audio, une analyse des émotions faciales et une analyse du sentiment du texte.</p>

        <form id="uploadForm" class="space-y-4">
            <label for="videoFile" class="block text-gray-700 font-medium text-lg">Sélectionnez une vidéo :</label>
            <input type="file" id="videoFile" name="video" accept="video/*" class="w-full p-3 border border-gray-300 rounded-md focus:ring-indigo-500 focus:border-indigo-500" required>
            
            <button type="submit" id="analyzeButton" class="w-full bg-indigo-600 text-white p-3 rounded-md font-semibold hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-indigo-500 focus:ring-offset-2 transition-colors">
                Analyser la Vidéo
            </button>
        </form>

        <div id="loadingMessage" class="hidden mt-6 flex items-center justify-center text-indigo-600 font-medium">
            <div class="spinner mr-3"></div>
            Analyse en cours... Cela peut prendre un certain temps.
        </div>

        <div id="errorMessage" class="hidden mt-6 p-4 bg-red-100 border border-red-400 text-red-700 rounded-md" role="alert">
            <strong class="font-bold">Erreur :</strong>
            <span id="errorText" class="block sm:inline"></span>
        </div>

        <div id="results" class="mt-8 pt-8 border-t border-gray-200 hidden">
            <h2 class="text-2xl font-bold text-gray-800 mb-4">Résultats de l'Analyse</h2>
            <div id="transcriptionResult" class="mb-6 p-4 bg-gray-50 rounded-md">
                <h3 class="text-xl font-semibold text-gray-700 mb-2">1. Transcription de l'Entretien</h3>
                <p id="transcriptionText" class="text-gray-800 leading-relaxed"></p>
            </div>

            <div id="facialEmotionsResult" class="mb-6 p-4 bg-gray-50 rounded-md">
                <h3 class="text-xl font-semibold text-gray-700 mb-2">2. Analyse des Émotions Faciales</h3>
                <p id="facialEmotionsSummary" class="text-gray-800 leading-relaxed"></p>
            </div>

            <div id="sentimentResult" class="mb-6 p-4 bg-gray-50 rounded-md">
                <h3 class="text-xl font-semibold text-gray-700 mb-2">3. Analyse du Sentiment Général du Texte</h3>
                <p id="overallSentiment" class="text-gray-800 leading-relaxed"></p>
                <div id="rawSentimentScores" class="text-gray-700 text-sm mt-2"></div>
            </div>
        </div>
    </div>

    <script>
        const uploadForm = document.getElementById('uploadForm');
        const videoFileInput = document.getElementById('videoFile');
        const analyzeButton = document.getElementById('analyzeButton');
        const loadingMessage = document.getElementById('loadingMessage');
        const errorMessage = document.getElementById('errorMessage');
        const errorText = document.getElementById('errorText');
        const resultsDiv = document.getElementById('results');
        const transcriptionTextElem = document.getElementById('transcriptionText');
        const facialEmotionsSummaryElem = document.getElementById('facialEmotionsSummary');
        const overallSentimentElem = document.getElementById('overallSentiment');
        const rawSentimentScoresElem = document.getElementById('rawSentimentScores');

        // Function to display error messages
        function displayError(message) {
            errorMessage.classList.remove('hidden');
            errorText.textContent = message;
            resultsDiv.classList.add('hidden'); // Hide results if an error occurs
        }

        // Function to hide error messages
        function hideError() {
            errorMessage.classList.add('hidden');
            errorText.textContent = '';
        }

        uploadForm.addEventListener('submit', async (event) => {
            event.preventDefault(); // Prevent default form submission

            hideError(); // Clear any previous errors
            resultsDiv.classList.add('hidden'); // Hide previous results
            loadingMessage.classList.remove('hidden'); // Show loading spinner
            analyzeButton.disabled = true; // Disable button during analysis

            const videoFile = videoFileInput.files[0];

            if (!videoFile) {
                displayError('Veuillez sélectionner un fichier vidéo.');
                loadingMessage.classList.add('hidden');
                analyzeButton.disabled = false;
                return;
            }

            const formData = new FormData();
            formData.append('video', videoFile); // 'video' must match the FastAPI endpoint's parameter name

            try {
                const response = await fetch('http://127.0.0.1:8000/analyze-interview-video', {
                    method: 'POST',
                    body: formData,
                });

                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.detail || `Erreur du serveur: ${response.status} ${response.statusText}`);
                }

                const data = await response.json();
                displayResults(data);

            } catch (error) {
                console.error('Error during API call:', error);
                displayError(`Échec de l'analyse : ${error.message}`);
            } finally {
                loadingMessage.classList.add('hidden'); // Hide loading spinner
                analyzeButton.disabled = false; // Re-enable button
            }
        });

        function displayResults(data) {
            resultsDiv.classList.remove('hidden');

            // 1. Transcription
            transcriptionTextElem.textContent = data.transcription.text;

            // 2. Facial Emotions
            const videoDuration = data.video_emotions.video_duration_seconds;
            const emotionsTimeline = data.video_emotions.emotions_timeline;

            let facialSummary = `Sur une durée de **${videoDuration} secondes**, en analysant ${emotionsTimeline.length} images clés (une par seconde) : `;

            let emotionCounts = {};
            emotionsTimeline.forEach(frameData => {
                frameData.detected_faces.forEach(faceData => {
                    const emotion = faceData.emotion;
                    emotionCounts[emotion] = (emotionCounts[emotion] || 0) + 1;
                });
            });

            let dominantEmotion = null;
            let maxCount = 0;
            if (Object.keys(emotionCounts).length > 0) {
                for (const emotion in emotionCounts) {
                    if (emotionCounts[emotion] > maxCount) {
                        maxCount = emotionCounts[emotion];
                        dominantEmotion = emotion;
                    }
                }
                facialSummary += `L'émotion faciale la plus fréquemment détectée était la **${dominantEmotion.charAt(0).toUpperCase() + dominantEmotion.slice(1)}**.\n`;
            } else {
                facialSummary += `Aucun visage significatif n'a été détecté ou aucune émotion dominante claire.\n`;
            }

            let keyEmotionTimestamps = {};
            emotionsTimeline.forEach(frameData => {
                frameData.detected_faces.forEach(faceData => {
                    const emotion = faceData.emotion;
                    if (dominantEmotion && emotion !== dominantEmotion) {
                        if (!keyEmotionTimestamps[emotion]) {
                            keyEmotionTimestamps[emotion] = new Set(); // Use Set to avoid duplicate timestamps
                        }
                        keyEmotionTimestamps[emotion].add(frameData.timestamp_seconds);
                    }
                });
            });

            if (Object.keys(keyEmotionTimestamps).length > 0) {
                facialSummary += "Cependant, il est important de noter des moments où d'autres émotions ont été observées :\n";
                for (const emo in keyEmotionTimestamps) {
                    const sortedTimestamps = Array.from(keyEmotionTimestamps[emo]).sort((a,b) => a-b).join(', ');
                    facialSummary += `* Des expressions de **${emo.charAt(0).toUpperCase() + emo.slice(1)}** ont été détectées autour des secondes : **${sortedTimestamps}**.\n`;
                }
                facialSummary += "\nCes variations émotionnelles sont intéressantes à considérer en regard du discours.\n";
            } else if (dominantEmotion) {
                facialSummary += `\nL'émotion ${dominantEmotion.charAt(0).toUpperCase() + dominantEmotion.slice(1)} a été prédominante tout au long des moments analysés.\n`;
            }
            
            // Render markdown-like bold using innerHTML
            facialEmotionsSummaryElem.innerHTML = facialSummary.replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>');


            // 3. Overall Sentiment
            const overallSentiment = data.overall_text_sentiment.overall_sentiment;
            const confidenceScore = data.overall_text_sentiment.confidence_score;
            const rawScores = data.overall_text_sentiment.raw_scores;

            overallSentimentElem.innerHTML = `Sur la base de la transcription de votre réponse, le sentiment général détecté est <strong>${overallSentiment.charAt(0).toUpperCase() + overallSentiment.slice(1)}</strong>, avec un score de confiance de <strong>${(confidenceScore * 100).toFixed(1)}%</strong>.`;

            rawSentimentScoresElem.innerHTML = '<p class="font-semibold mb-1">Détails des scores de sentiment :</p>';
            let scoresList = '<ul>';
            for (const label in rawScores) {
                scoresList += `<li>${label.charAt(0).toUpperCase() + label.slice(1)}: ${(rawScores[label] * 100).toFixed(1)}%</li>`;
            }
            scoresList += '</ul>';
            rawSentimentScoresElem.innerHTML += scoresList;
        }
    </script>
</body>
</html>
